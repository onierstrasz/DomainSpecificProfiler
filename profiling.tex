% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\documentclass[runningheads]{llncs}

\newcommand{\project}{{\sc MetaSpy}\xspace}

% packages
\usepackage{xspace}
\usepackage{ifthen}
\usepackage{amsbsy}
\usepackage{amssymb}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{needspace}
\usepackage{microtype}
\usepackage{bold-extra}

% constants
\newcommand{\Title}{Domain-Specific Profiling}
\newcommand{\TitleShort}{\Title}
\newcommand{\Authors}{Alexandre Bergel$^1$, Lukas Renggli, Jorge Ressia$^2$}
\newcommand{\AuthorsShort}{A. Bergel, L. Renggli, J. Ressia}

% references
\usepackage[colorlinks]{hyperref}
\usepackage[all]{hypcap}
\setcounter{tocdepth}{2}
\hypersetup{
	colorlinks=true,
	urlcolor=black,
	linkcolor=black,
	citecolor=black,
	plainpages=false,
	bookmarksopen=true,
	pdfauthor={\Authors},
	pdftitle={\Title}}

\def\chapterautorefname{Chapter}
\def\appendixautorefname{Appendix}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}
\def\figureautorefname{Figure}
\def\tableautorefname{Table}
\def\listingautorefname{Listing}

% source code
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\definecolor{source}{gray}{0.9}
\lstset{
	language={},
	% characters
	tabsize=3,
	upquote=true,
	escapechar={!},
	keepspaces=true,
	breaklines=true,
	alsoletter={\#:},
	breakautoindent=true,
	columns=fullflexible,
	showstringspaces=false,
	basicstyle=\footnotesize\sffamily,
	% background
	frame=single,
    framerule=0pt,
	backgroundcolor=\color{source},
	% numbering
	numbersep=5pt,
	numberstyle=\tiny,
	numberfirstline=true,
	% captioning
	captionpos=b,
	% formatting (html)
	moredelim=[is][\textbf]{<b>}{</b>},
	moredelim=[is][\textit]{<i>}{</i>},
	moredelim=[is][\color{red}\uwave]{<u>}{</u>},
	moredelim=[is][\color{red}\sout]{<del>}{</del>},
	moredelim=[is][\color{blue}\underline]{<ins>}{</ins>}}
\newcommand{\ct}{\lstinline[backgroundcolor=\color{white},basicstyle=\footnotesize\ttfamily]}
\newcommand{\lct}[1]{{\small\tt #1}}

% tikz
% \usepackage{tikz}
% \usetikzlibrary{matrix}
% \usetikzlibrary{arrows}
% \usetikzlibrary{external}
% \usetikzlibrary{positioning}
% \usetikzlibrary{shapes.multipart}
% 
% \tikzset{
% 	every picture/.style={semithick},
% 	every text node part/.style={align=center}}

% proof-reading
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\newcommand{\ra}{$\rightarrow$}
\newcommand{\ugh}[1]{\textcolor{red}{\uwave{#1}}} % please rephrase
\newcommand{\ins}[1]{\textcolor{blue}{\uline{#1}}} % please insert
\newcommand{\del}[1]{\textcolor{red}{\sout{#1}}} % please delete
\newcommand{\chg}[2]{\textcolor{red}{\sout{#1}}{\ra}\textcolor{blue}{\uline{#2}}} % please change
\newcommand{\chk}[1]{\textcolor{ForestGreen}{#1}} % changed, please check

% comments \nb{label}{color}{text}
\newboolean{showcomments}
\setboolean{showcomments}{true}
\ifthenelse{\boolean{showcomments}}
	{\newcommand{\nb}[3]{
		{\colorbox{#2}{\bfseries\sffamily\scriptsize\textcolor{white}{#1}}}
		{\textcolor{#2}{\sf\small$\blacktriangleright$\textit{#3}$\blacktriangleleft$}}}
	 \newcommand{\version}{\emph{\scriptsize$-$Id$-$}}}
	{\newcommand{\nb}[2]{}
	 \newcommand{\version}{}}
\newcommand{\rev}[2]{\nb{Reviewer #1}{red}{#2}}
\newcommand{\ab}[1]{\nb{Alexandre}{blue}{#1}}
\newcommand{\lr}[1]{\nb{Lukas}{orange}{#1}}
\newcommand{\jr}[1]{\nb{Jorge}{cyan}{#1}}

% graphics: \fig{position}{percentage-width}{filename}{caption}
\DeclareGraphicsExtensions{.png,.jpg,.pdf,.eps,.gif}
\graphicspath{{figures/}}
\newcommand{\fig}[4]{
	\begin{figure}[#1]
		\centering
		\includegraphics[width=#2\textwidth]{#3}
		\caption{\label{fig:#3}#4}
	\end{figure}}

% abbreviations
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\etc}{\emph{etc.}\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}

% lists
\newenvironment{bullets}[0]
	{\begin{itemize}}
	{\end{itemize}}

\newcommand{\seclabel}[1]{\label{sec:#1}}
\newcommand{\co}[1]{{\sf #1}}


% D O C U M E N T
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\begin{document}

% T I T L E
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\title{\Title}
\titlerunning{\TitleShort}

\author{\Authors} 
\authorrunning{\AuthorsShort}

\institute{$^1$ PLEIAD Lab, University of Chile, Santiago, Chile\\
	\url{http://pleiad.dcc.uchile.cl} \\[0.3cm]
	$^2$ Software Composition Group, University of Bern, Switzerland\\
	\url{http://scg.unibe.ch}\\[0.3cm]
%	\url{abergel@dcc.uchile.cl}\\
%	\url{renggli@me.com}\\
%	\url{jorge.ressia@gmail.com}
	}

\maketitle

% A B S T R A C T
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\begin{abstract}
	Domain-specific languages and models are increasingly used within general-purpose host languages. While traditional profiling tools perform well on host language code itself, they often fail to provide meaningful results if the developers start to build and use abstractions on top of the host language. In this paper we motivate the need of dedicated profiling tools with three different case-studies. Furthermore, we present an infrastructure that enables developers to quickly prototype new profilers for their domain-specific languages and models.
\end{abstract}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Introduction}\seclabel{introduction}

% \jr{We need to argument something like this:}
% 
% I don't remember why with mondrian the traditional profiler fails, but with PP the argumentation for the intro could go as follows:
% 
% - pp uses the interpreter/command pattern, thus "logical" execution happens on an abstraction level not exposed to profilers
% 
% - the primitive entity of execution is a parser object, not a bytecode/messge send as a tradition profiler would analyze
% 
% - similar coverage is only meaningful on parser objects, not on host language source code
% 
% What we want:
% 
% - instead of bytecodes we have primitive/atomic parsers
% 
% - instead of method invokations we have grammar productions composed of parsers.
% 
% - now "messagetally" -> "prodctiontally" and "byecodetally" -> "pasertally" gives a meaning to developers (maybe note here that this is for grammar developers, the developers of PP do still use traditional tools).
% 
% - coverage needs to be displayed in terms of parsers/productions
% 
% - high level info needs to be mapped back to models (or the code that creates these models)
% 
% \jr{end}

The advances of domain-specific languages and models reveals a drastic change in the way software is being built. The software engineering community has seen a rapid emergence of domain-specific tools, ranging from tools to easily build domain-specific languages~\cite{Viss04a}, transform models~\cite{Tisi10a}, to program checking~\cite{Reng10b} and tool integration~\cite{Reng10a}.

While research on domain-specific languages made consistent progress on language specification~\cite{Deur00a}, implementation~\cite{Cuad09a}, evolution~\cite{Free06a} and verification~\cite{Kaba08a}, little has been done on profiling. We consider profiling as the activity to record and analyze program execution. Profiling is essential to analyze transient run-time data that otherwise would be to hard to harvest and compare. Code profilers commonly employ executing sampling as the way to obtain dynamic run-time information. Unfortunately, information extracted when regularly sampling the call stack cannot be meaningfully used to profile a high-level domain built on top of the standard language infrastructure.

\lr{I would don't really see how Mondrian demonstrates the problem. I would outline the problem as given in the commented bullet list at the beginning of this section.}

As an introductionary illustration, consider the Mondrian visualization engine\footnote{Mondrian will be detailed in the coming section (\autoref{mondrian}).}. A visualization is described in terms of nodes and edges. One of the important performance issues we recently faced is the refresh frequency: nodes and edges were refreshed too often.
%\footnote{\lr{I would avoid footnotes (they look ugly) and just say that there were complaints.} This has triggered a large discussion on the Moose mailing list (\url{http://bit.ly/fwsRbp}).}. 
Standard code profilers did not help to fix this since they are just able to give the share the CPU spent in the method \co{\#displayOn:} of the class \co{MONode} and \co{MOEdge}. The problem has been solved without standard profiler by identifying \emph{which} nodes and edges were indeed refreshed too often. Knowing the presence of some particular frames on the method call stack (as the majority of code profiler provide) has not been useful \lr{why not?}. The Mondrian domain particularities \lr{what are these?} are superfluous by standard code profiler which are only concerned with stack frames and source code artifacts.

%The domain, defined in terms of nodes and edges, \ugh{used by Mondrian is completely ignored by standard code profiler since they can only consider classes, method and stack frame}. This problem \ugh{, and many more,} has been successfully addressed with adequate domain-specific profilers.

This paper propose a general solution for profiling specific domains. It gives the essential properties an effective domain-specific profiler must meet. 
%\lr{do not understand:} It is important to notice that, \ugh{as metamodels are becoming first class entities}, a profiler's measurement dimension cannot be solely limited to execution time. 
We identified the following properties a domain-specific profiler must be designed around: \emph{identifiable domain}, \emph{recordable domain events}, \emph{presentable} \lr{you mean \emph{accessible domain state}?} and \emph{evolvable} \lr{what?}. By fulfilling these properties, a profiler will be effective at identifying bottlenecks and anomalies in the application code and be able to present these in therms of the application code.
These properties will be illustrated in three domains: Mondrian visualizations, OmniBrowser browser models, and PetitParser grammars. These profilers were designed to assess the quality of the domain modeling. A number of bugs and issues have been identified and fixed.

The contributions of this paper are: (1) the identification of the need for domain-specific profilers, (2) the presentation of three real-world case-studies where domain-specific profilers helped to significantly improve performance and correctness of domain-specific code, and (3) the presentation of an infrastructure for prototyping domain-specific profilers.

The remainder of this paper is structured as follows: \autoref{sec:problem} illustrates the problems of using a general-purpose profiler on code building on top of domain-specific language. \autoref{sec:profiler} introduces our approach to domain-specific profiling with three case-studies. \autoref{sec:implementation} presents our infrastructure to implement domain-specific profilers; and \autoref{sec:conclusion} summarizes the paper and discusses future work.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem}\seclabel{problem}

Current application profilers are useful to gather runtime data (\eg method invocations, method coverage, call trees, memory consumption) from the static code model offered by the programming language (\eg packages, classes, methods, statements). This is an effective approach when the low-level source code has to be profiled.

However, traditional profilers are hardly useful on a domain different than the code model. In many today's software there is a significant gap between the model offered by the execution platform and the model of the actually running application. 
The proliferation of meta-models and domain-specific languages brings new abstractions that map to the underlying execution platform in non-trivial ways. Traditional profiling tools fail to display relevant information in the presence of such abstractions.


%:=========
\subsection{Difficulty of profiling a specific domain} \label{mondrian}

This section illustrates two shortcomings of traditional profiling techniques when applied to a specific domain.\\

\paragraph{CPU time profiling.}
Mondrian\footnote{\url{http://www.moosetechnology.org/tools/mondrian}}~\cite{Meye06a} is an open and agile visualization engine. 
Mondrian uses a graph, made of (possibly nested) nodes and edges, to describe a visualization. 
In June 2010 a serious performance issue was identified\footnote{\lr{again?} \url{http://bit.ly/g8GjIh}} when performing a visualization.
Tracking down the cause of the poor performance was not trivial. We first used the sample-based code profiled provided by Pharo\footnote{\url{http://pharo-project.org/}}.

Execution sampling approximates the time spent in an application's methods by periodically stopping a program and recording the current set of methods under executions. Such a profiling technique is relatively accurate since it has little impact on the overall execution.
Beside Smalltalk profiler execution sampling has been adopted by almost all mainstream profilers (JProfiler\footnote{\url{http://www.ej-technologies.com}}, YourKit\footnote{\url{http://www.yourkit.com}}, xprof~\cite{Gupt92a}, hprof\footnote{\url{http://java.sun.com/developer/technicalArticles/Programming/HPROF.html}}).

The profiler produces a textual output, we next show an except of it:

\begin{lstlisting}
54.8% {11501ms} MOCanvas>>drawOn: 
  54.8% {11501ms} MORoot(MONode)>>displayOn: 
   30.9% {6485ms} MONode>>displayOn: 
      | 18.1% {3799ms} MOEdge>>displayOn: 
     	...    
      |  8.4% {1763ms} MOEdge>>displayOn: 
      |    | 8.0% {1679ms} MOStraightLineShape>>display:on: 
      |    |  2.6% {546ms} FormCanvas>>line:to:width:color: 
    	...    
   23.4% {4911ms} MOEdge>>displayOn: 	
        ...    
\end{lstlisting}

It essentially says that the virtual machine spent about 54\% of its time in the method \ct{#displayOn:} defined in the class \ct{MORoot}. A root is the unique non-nested node that contains all the nodes of the edges of the visualization. This general profiling information says that rendering nodes and edges consumes a great share of the CPU, but it does not help pinpointing which nodes and edges are culprit of the time taken. Not all the graphical elements equally consume resources.

Traditional execution sampling profilers center their result on the frames of the execution stack and completely ignore the identify of the object that received the method call and its arguments. As a consequence, it is hard to track down what are the objects culprit of the slowness. On the example above, MessageTally says that we spent 30.9\% in \ct{MONode>>displayOn} without saying which nodes were actually refreshed too often.
\jr{@Alex I think that here we should have some gluing sentence that explain how stack based profilers like MessageTally were not useful. Then this two parts in the paragraph will flow better. Just one or two sentences will be enough. Maybe saying how you found the problem at the end might help to contrast to MessageTally data.}\ab{Is this better?}
%We found out that graphical shape properties such as line width, fill color, border color were constantly computed, even though the model did not change. 
%This performance issue has been solved a few days after the complain via a quantification of the displayOn: invocation on each objects and metric computation. The information collected by MessageTally was not useful to solve the problem. 

%\lr{The Mondrian example is not convincing at all. I don't see why a detected profiler provides more useful information than the standard MessageTally. I think PetitParser would be a better example, because here in the MessageTally you truly don't see anything. And the Coverage is an extension to that.}

\paragraph{Coverage.} 
%\jr{rewrite, it is not clear what are we aiming here.} \ab{I worked on this section. Is this better? If yes, remove the comments}
PetitParser is a parsing framework combining ideas from scannerless parsing, parser combinators, parsing expression grammars and packrat parsers to model grammars and parsers as objects that can be reconfigured dynamically \cite{Reng10c}. %PetitParser is designed to be fast: parsing a textual input is significantly faster than SmaCC, a widely used lalr parser implemented in Pharo.

A number of grammars have been implemented, including Java, Smalltalk, XML and SQL. 
%As being the result of a lengthy engineering process, a grammar may contain unnecessary rules and duplication \lr{this is not about duplication, but coverage!}. 
Getting the coverage of a grammar for a set of referential input text is useful to identify unused and duplicated parsing rules. The \ct{if} statement parsing rule is defined as follows:

\lr{Smalltalk is not introduced yet}

\begin{lstlisting}
<b>PPJavaSyntax>>ifStatement</b>
    ^ ('if' asParser token , conditionalExpression , statement) , 
	  ('else' asParser token , statement) optional
\end{lstlisting}

% \lr{uhh, this doesn't tell me anything:} This parsing rule is the combination of parsers combined with the message named comma (\ct{,}).

Coverage tools assess the coverage of the application source code by giving the list of methods involved in an execution. Some tools can even detect the coverage inside methods.
Lets consider the Java grammar\footnote{\url{http://www.squeaksource.com/PetitJava.html}} for PetitParser which is defined with 210 rules. These rules are modeled with a graph of objects. 
When in need of analyzing the parsing and production coverage of the Java Grammar parser traditional coverage tools only provide source code related data instead of domain-specific.


% Beside CPU consumption, sample-based profiling estimates the method coverage of an application: methods present in the call graph are covered by the referential input text. For example, the Java grammar\footnote{\url{http://www.squeaksource.com/PetitJava.html}} for PetitParser is defined with 210 rules. These rules are modeled with a graph of objects. Whereas MessageTally is relatively efficient in \ugh{estimating the coverage of source code} \lr{what????}, it is of a little help when applied to a graph of parsers, a domain other than classes and methods.
% 
% \lr{I don't see how MessageTally has anything to do with Coverage?}
% 
% For example, MessageTally produces a large output, in which what follows is an excerpt:
% 
% \begin{lstlisting}
%           ...    
%             |17.1% {34ms} PPJavaSyntaxTests(PPCompositeParserTest)>>parse:rule:
%             |  17.1% {34ms} PPSequenceParser(PPParser)>>parse:
%             |    17.1% {34ms} PPSequenceParser>>parseOn:
%             |        ....          
%             |            17.1% {34ms} PPChoiceParser>>parseOn:
%             |              17.1% {34ms} PPSequenceParser>>parseOn:
%             |           ....          
%             |                        16.6% {33ms} PPSequenceParser>>parseOn:
%             |                          14.6% {29ms} PPChoiceParser>>parseOn:
%             |                            14.6% {29ms} PPSequenceParser>>parseOn:
%             ...    
% \end{lstlisting}
% 
% MessageTally assess the coverage of the application source code by giving the list of methods involved in an execution. Some of the methods executed when executing the \ct{PPJavaSyntaxTests} are given. However, the coverage of the application source code can hardly be related to the coverage of the considered domain, object parsers in our case.

%:=========
\subsection{Requirements for domain-specific profilers}

The two examples given above are representative. They illustrate the gap between a particular domain and the source code model. We argue that to efficiently profile an arbitrary domain, the following requirements needs to be fulfilled:

\begin{itemize}
\item \emph{Specifying the domain.} Since we are concerned with what makes up a visualization in Mondrian, we are interested in the different nodes and the invocation of the \ct{displayOn:} methods, instead of focusing on the implementation classes. 

Parser objects in PetitParser are dynamically generated by applying the grammar rules on a given source text. Each parser is an instance of a subclass of \ct{Parser}. 

Being able to effectively designate the objects relevant for the profiling is essential.

\item \emph{Capturing domain related events.}
Whereas the class \ct{MOGraphElement} and its subclasses total more than 263 methods, only less than 10 methods are related to displaying and computing shape dimensions. 

 During the execution of the application, relevant changes and actions triggered by the domain have to be monitored and recorded. Monitoring too many events generates noise and distraction. 
 
\item \emph{Effectively and concisely presents the necessary information.} 
The information collected by traditional profilers is textual and targets method invocation. A method that invokes another will be located below it and indented. Moreover each method frame represented has a class name and a method name, which completely ignores the identity of the object and arguments that are part of the call.

Collected information have to be presented in such a way that the important metrics and domain object composition are on the foreground.  

%\item The evolution of the profile over time.
\end{itemize}

% It is important to emphasize that the limitations we identified are not particular to MessageTally \lr{that's why I would not use that name, just say `traditional profilers'. Otherwise reviewers are going to say that this is far too specific and their profiler is different.}. Following MessageTally, 

Common code profilers employ executing sampling as the way to cheaply obtain dynamic information. Unfortunately, information extracted when regularly sampling the method call stack cannot be used to profile a domain other than source code model.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Domain-Specific Profiler}\seclabel{profiler}

%:========
\subsection{Properties of a Domain-Specific Profiler} \label{fig:properties}

\jr{@Alex @Lukas I think that these are the solutions that we provide to solve the requirements previously mentioned. So I would suggest removing these points from here and stressing them in the approach and in the use cases.} \ab{Strange, I feel that the flow is okay}

We identified four distinct properties that domain-specific profilers must fulfill to be effective:


\paragraph{Identifiable domain.}
Elements that represent a domain of interest have to be retrieved from a current execution. Elements have to be identified independently of their implementation. These elements are usually expressed in terms of objets, accessible during the application execution. 

Dealing with circularity and meta-references is a common issue when a profiler is an instance of the model being profiled. To keep the model distinct from the profiler, a scoping mechanism has to be employed~\cite{Tant10a}.

%\paragraph{Domain specific metrics.} 
%\ab{We need to compute some metrics, else no much can be done}

\paragraph{Recordable domain events.} Relevant events generated by the domain have to be monitored and recorded to be analyzed during or after the execution. An event represents a particular change or action triggered by the domain being profiled. 


\paragraph{Presentable.} Information obtained during a code execution profiling needs to be adequately presented to be exploitable. A graph (composed of nodes and edges) is a structure general enough to describe meta-models \lr{uhh? do not understand!}.

The profiling information need to be mapped back to the profiled model. This implies that the presentation should provide enough information to be able to navigate between the profile to the model \lr{do not understand!}.

%\paragraph{Homogeneous event cost.} When considering the execution time of a particular event, each event must be treated as an atomic and uniform operation, independently of the object receiver. \ab{maybe not... We need to experiment on this} \lr{I don't get it.} \lr{Maybe more ``Domain-Specific Evaluation'', \ie arguing that time-to-run, number of activations, ... does not make sense; we need domain-specific values like characters/second, refreshes/click, ...}


\paragraph{Evolvable.} Being able to see the evolution of the domain events over the time is valuable, especially when precisely analyzing the sequence of domain events is complex or not feasible \lr{do not understand!}.

%:========
\subsection{The \project Framework}

\jr{There was a table here, it was removed, what was the idea behind it?} 
\ab{I am not sure it is worth mentioning the table. We essentially say it when formulating the problem.}

\ab{I feel there is more to say about \project}

\fig{}{1}{MetaSpy}{The \project framework.}

\project is a framework to easily build domain-specific profilers. 
\autoref{fig:MetaSpy} shows a simplified class diagram of \project.
There are two main abstractions: the observers and the domain-specific profilers.

An observer is responsible of adapting a domain-specific model and triggering specific actions when certain events happen.
These observers follow the observer pattern~\cite{Gamm95a} and the profilers are the subscribers.
%Fulfilling the specific but these are not conditions that are constantly checked, these are events being triggered from the model} of an observer will trigger the handler defined in that observer.
Some observers work by mean of registering to existing hooks. Other observers intercept the system using meta-programming, this is also known as instrumentation.
Installing an observer activates the observer and the collection of events, while uninstalling removes the observer. 


Some of the observers are:
\begin{description}
	\item[Announcement Observer.] Announcements provide a flexible framework for event handling. The announcement observer allows to hook into applications using this infrastructure and to dispatch them to the profiler.
	\item[Method Observer.] This observer listens to the event when an specific method is invoked for any instance of a class.
	\item[Object Observer.] This observer allows us to trigger event for a single instance of a class. This is called object-specific profiling. Some examples of event a single instance can trigger are: message send, message receive, state read and state write.
	\item[Parser Observer.] The parser observers triggers an event whenever a specific production is activated.
	%\item[Message Receive Observer.] \lr{I don't see the difference to the object observer, I would remove this one.} This observer models when a message is received by a single instance of a class. The message name and receiver can be taken into account in the definition of the condition. 
	%\item[Message Send Observer.] \lr{I don't see the difference to the object observer, I would remove this one.} This observer models when a message is sent by a single instance of a class. We can scope this instrumentation to a single or more methods.
	The message name, sender and receiver can be taken into account in the definition of the condition. 
\end{description}

Profilers are responsible for modeling the domain-specific behavior to profile the main abstractions in the each domain.
\ct{MetaSpy} class models the general behavior of any profiler. It is composed of a model which is being profiled and a list of active observer or instrumentation strategies.
Each of the different profilers are called spies. They are activated when they are installed. The installation process for each spy is defined in the \ct{setUp} method.
Each spy is responsible for its own presentation and this is modeled in the method \ct{visualize}.

We will next show specific examples of various domain-specific profilers\footnotetext{Readers unfamiliar with the syntax of Smalltalk might want to read the code examples aloud and interpret them as normal sentences: An invocation to a method named \ct{method:with:}, using two arguments looks like: \ct{receiver method: arg1 with: arg2}. The semicolon separates cascaded messages that are sent to the same receiver. For example, \ct{receiver method1: arg1; method2: arg2} sends the messages \ct{method1:} and \ct{method2:} to \ct{receiver}. Other syntactic elements of Smalltalk are: the dot to separate statements: \ct{statement1. statement2}; square brackets to denote code blocks or anonymous functions: \ct{[ statements ]}; and single quotes to delimit strings: \ct{'a string'}. The caret \ct{^} returns the result of the following expression.}.

%\begin{tabular}{c|c|c}
%					&	\textbf{Host language} 	& \textbf{DSL} \\ \hline
%					&						& 		\\
%\textbf{$M_0$ - Static}	&	classes, methods		& 		\\
%					&						& 		\\\hline
%					&						& Mondrian\\
%\textbf{$M_1$ - Dynamic}	&	method activation		& OB-metamodel\\
%					&						& Grammars\\ \hline
%					&						& OB Browser\\
%\textbf{$M_2$ -} 		&						& Visualization\\
%					&						& Mondrian
%\end{tabular}


%:========
\subsection{Case Study: Caches in Mondrian}

%\jr{Is this example related to the one in section 2? if yes how, we have to build the flow here otherwise is a bunch of separated examples.} \ab{Is this better now? If yes, remove these 2 comments}

The performance issue of Mondrian described earlier (\autoref{sec:problem}) is rooted in a complex combination of different aspects of Mondrian rendering: redundancy of metrics calculation and unnecessary graphical elements repaint. Theses two aspects were independently addressed, using a dedicated profiler.

\paragraph{Keeping track of the caches activations.}
Each node has a number of caches. Activation of theses caches are under complex rules which depends on what is currently displayed, the nesting of nodes and their size. An improper implementation of the caches is a source of hard-to-track bugs and abnormal behavior. Mondrian offer two kind of caches:
\begin{itemize}
\item A node may nest other nodes and edges. The \emph{bitmap form cache} avoid to render inner nodes by snapshooting a bitmap of the nesting node. Once the bitmap cache loaded, inner nodes are not rendered any further.
\item The shape of a graphical element is the result of metric calculation on the model object represented by the element. Each dimension of a graphical element is mapped to a metric. The \emph{metric cache} avoid having to recompute the metrics at each rendering.
\end{itemize}

Keeping track of the activation and deactivation of theses two caches is realized with a dedicated profiler, called {\sc MondrianCacheActivation}. The profiler is implemented as a class \co{MSMondrianActivationCacheSpy}. The class inherits from \co{MSAbstractMondrianSpy}, which will be used for the second profiler.

{\sc MondrianCacheActivation} is defined as follows \lr{what does this demonstrate?}:

\begin{lstlisting}[numbers=left]
<b>MSMetaSpy subclass: #MSAbstractMondrianSpy</b>
	instanceVariableNames: 'nodes'
	
<b>MSAbstractMondrianSpy>>setUp</b>
	super setUp.
	nodes := self model root allNodes.
	
<b>MSAbstractMondrianSpy subclass: #MSMondrianCacheActivationSpy</b>

<b>MSMondrianActivationCacheSpy>>visualizeOn: view</b>
	view interaction every: 1500 do: [
		view root clear.
		view shape rectangle
			if: #hasCachedForm fillColor: Color red.

		view nodes: nodes forEach: [:each |
			view nodes: each metricCaches.
			view gridLayout gapSize: 2.
		].  
		view edges: nodes from: #owner to: #yourself.
		view treeLayout.
		view root applyLayout ]
\end{lstlisting}

\lr{Why is this better than what the Squeak damage visualizer and the OS X GUI damage visualizer provides?}\ab{I do not know about the squeak and OSX damage visualizer. How can I invoke it? I tried some googling but found nothing}

The code opens a new Mondrian visualization that visualizes the profiling the nodes of another visualization, given by an \co{nodes} instances variable. The \emph{domain} that is profiled are the node. Lines 7 and 12 describes the following steps: nodes are displayed and the ownership (nesting) is represented with edges. The domain is profiled against two relevant properties. These are represented in Lines 14 and 17: a bitmap form and metrics. The profile is presented via the Mondrian script given above. The evolution over execution is realized via a periodical refresh, indicated in the script at Line 11. The model being profiled and the profiler are represented with different objects in the host language. The scope of the profiling is naturally given by operating on a different object.

\fig{}{.8}{MondrianExample}{Profiling of a Mondrian visualization in Mondrian.}

The profile visualization is given in \autoref{fig:MondrianExample}. The upper part is a visualization example, part of Mondrian tutorial. The below part is a profile of it. Upper nodes are nesting nodes. The red color indicates that the bitmap form cache is activated, and inner nodes represent metric caches. We can see that the fourth red node does not have any metric cache activated. This helped us to fix a number of issues related to the way caches are managed. These issues have been fixed in the Version 6, 9 and 10 of the package Mondrian-Core\footnote{All Mondrian versions are available online at \url{http://www.squeaksource.com/Mondrian.html}.}.


\paragraph{Number of \co{\#displayOn:} invocation.}
A Mondrian visualization may comprise a great deal of graphical elements. At each refresh of the Mondrian visualization dictated by the operating system, only the elements that needs to be refreshed must effectively be. Elements that are outside the window or for which their nesting node has an active bitmap form cache should not be rendered. 

A graphical element is rendered when the method \co{\#display:on:} is invoked. Monitoring when these invocations occur is key to have a global view of what get refreshed. 

The \project framework is instantiated to create the {\sc MondrianDisplayOn} profiler, implemented with a class \co{\sf MSMondrianSpy}:

\begin{lstlisting}
MSAbstractMondrianSpy subclass: #MSMondrianDisplayOnSpy
	instanceVariableNames: 'actualCounter previousCounter'
\end{lstlisting}

{\sf MSMondrianSpy} defines two instance variables: {\sf actualCounter} keeps track of the actual amount of events and {\sf previousCounter} the amount of events that were recorded before a new action in the profiled Mondrian visualization. These two variables are necessary to monitor the evolution of the amount of emitted events (the \emph{Profile evolution} property, listed in \autoref{fig:properties}). Subtracting the value stored in {\sf previousCounter} from {\sf actualCounter} gives the difference from two Mondrian refreshs.

\begin{lstlisting}
<b>MSMondrianSpy>>initialize</b>
	super initialize.
	actualCounter := IdentityDictionary new.
	previousCounter := IdentityDictionary new
\end{lstlisting}

The installation and instrumentation of Mondrian by \project is realized by the {\sf setUp} method:

\begin{lstlisting}
<b>MSMondrianSpy>>setUp</b>
	self model root allNodes do: [ :node |
		self 
			observeObject: node
			selector: #displayOn:
			do: [ :receiver :selector :arguments |
				actualCounter 
					at: receiver
					put: ((actualCounter at: receiver ifAbsentPut: [ 0 ]) + 1) ] ]
\end{lstlisting}

All the nodes obtained from the root of the model object are ``observed'' by the framework. At each invocation of the {\sf \#displayOn:} method, the block given as parameter to {\sf \#do:} is executed with the object receiver on which {\sf \#displayOn:} is invoked, the selector name and the argument. This block updates the number of displays for each node of the visualization.

The profiling of Mondrian is visualized using Mondrian itself. The following \co{\#visualizeOn:} method describes the visualization given in \autoref{fig:MondrianProfiler}.

\lr{Please no source code with dots.}
\lr{What does this show?}
\begin{lstlisting}
MSMondrianSpy>>visualizeOn: view
	view interaction every: 250 do: [ 
	...
	view nodes: self model root allNodes forEach: [ :each |
		... ].
	view verticalLineLayout.	
	view announcer on: WindowClosed do: [:ann | self uninstall ]
\end{lstlisting}

\fig{}{.8}{MondrianProfiler}{Profiling the \emph{System Complexity} visualization.}

One important point of \co{\#visualizeOn:} is to regularly update the visualization, complying with the \emph{Profile evolution} property. The profiler is uninstalled when the profiler Mondrian visualization is closed.

\autoref{fig:MondrianProfiler} gives a screenshot of a visualization and the profiler. The right-hand side is an example of the \emph{System Complexity} visualization~\cite{Lanz03d} of the collection class hierarchy in Pharo. The left hand side shows the profiler applied to the visualization. The horizontal bar indicates the amount of times the corresponding node has been displayed. %This visualization has been obtained by dragging and dropping the \ct{Collection} node

\jr{@Alex can you provide a brief justification on why this visualization is better helps to identify this problems?} 
This visualization helps identifying unnecessary render of graphical element. This problem is addressed in the version 2.30 of Mondrian\footnote{\url{http://code.google.com/p/moose-technology/issues/detail?id=450}}. 

%:========
\subsection{Case Study: Events in Omnibrowser}

OmniBrowser~\cite{Berg08c} is a framework to define and compose new browsers: graphical list-oriented tools to navigate and edit elements from an arbitrary domain. In the OmniBrowser framework, a browser is described by a domain model that specifies the domain elements that can be navigated and edited, and a metagraph that specifies the navigation between these domain elements. Nodes in the metagraph describe states the browser is in, while edges express navigation possibilities between those states. The OmniBrowser framework then dynamically composes widgets such as list menus and text panes to build an interactive browser that follows the navigation described in the metagraph.

%\lr{What does this show?}

\begin{lstlisting}
MSMetaSpy subclass: #MSOmniBrowserSpy
	instanceVariableNames: 'actualCounter previousCounter'
\end{lstlisting}

\begin{lstlisting}
<b>MSOmniBrowserSpy>>setUp</b>
	self 
		observeAnnouncer: self model announcer
		do: [ :ann | 
			actualCounter
				at: ann class
				put: (actualCounter at: ann class ifAbsentPut: [ 0 ]) + 1 ]
\end{lstlisting}

%\paragraph{Meta-model instantiation}:
%\begin{lstlisting}
%	model := OBSystemBrowser onClass: Object selector: #printOn:.
%	profile := OmniProfiler 
%		profile: [ window :=  model open ]
%		inPackage: 'OmniBrowser'.
%\end{lstlisting}
%
%\paragraph{Recording events}:
%\begin{lstlisting}
%	model := OBSystemBrowser onClass: Object.
%	actualCounter := Dictionary new.
%	previousCounter := Dictionary new.
%	model announcer
%		observe: OBAnnouncement
%		do: [ :ann | actualCounter at: ann class put: (actualCounter at: ann class ifAbsentPut: [ 0 ]) + 1 ].
%\end{lstlisting}

\jr{@Lukas can you take care of this use case. What was the idea behind this example?}

%\lr{so what?}

%:========
\subsection{Case Study: Parsing Framework with PetitParser}

Rigorous test suites try to ensure that each part of the grammar is covered by tests and well specified according to the respective language standards. Validating that each production of the grammar is covered by the tests is a difficult activity. As mentioned previously, the traditional tools of the host language work on a method- and statement-level and thus cannot produce meaningful results in the context of PetitParser where the grammar is modeled as a graph of objects.

With \project we can implement the grammar coverage with a few lines of code. The instrumentation happens at the level of the primitive parser objects. The method \ct{observeParser:in:} wraps the parser object with a handler block that is called for each activation of the parser.

\begin{lstlisting}[numbers=left]
<b>PetitParserSpy>>setUp</b>
	self grammar allParsers do: [ :parser |
		self observeParser: parser in: self grammar do: [
			counter at: parser put: (counter at: parser ifAbsent: [ 0 ]) + 1 ] ]
\end{lstlisting}

Line~2 iterates over all primitive parser objects in the grammar. Line~3 attaches the event handler on Line~4 to each parser in the model. The handler then counts the activations of each parser object when we run the test suite of the grammar. This provides us with the necessary information to display the grammar coverage in a visualization as seen in \autoref{fig:grammar-coverage}.

\lr{Why now the XML parser and before it was the Java parser?}
\jr{@Lukas Do you think this should be changed? what would be the cost?}

\begin{figure}[h!tb]
	\centering
	\includegraphics[width=0.4\textwidth]{xml-uncovered}
	\hspace{0.1\textwidth}
	\includegraphics[width=0.4\textwidth]{xml-covered}
	\caption{Production coverage of an XML grammar with uncovered productions highlighted in black (left); and the same XML grammar with updated test coverage and complete production coverage (right). The size of the nodes is proportional to the number of activations when running the test suite on the grammar.}
	\label{fig:grammar-coverage}
\end{figure}

\ab{Which version of PetitParser correspond to the left hand side in Figure 4?} 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% \section{Discussion}\seclabel{discussion}
% 
% \jr{What is the objective of this section?}
% 
% \paragraph{Getting the information.} 
% Depend on the application to be profiled. 
% Can use events if the application to be profiled has been accordingly designed. This is the case of Omnibrowser. 
% 
% Can use bytecode instrumentation. But in that case, high level representation needs to be extracted by the programmer. A mapping has to be explicit. This is the case of PetitParser and Mondrian.




% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Implementation}\seclabel{implementation}

%\jr{the first paragraph does not make sense, change it.}
%\lr{that was already said}
% The implementation \project heavily relies on observers (Observer Design Pattern~\cite{Gamm95a}). 
% %The Observer Design Pattern~\cite{Gamm95a} defines an observer is a particular object that gets notified of any state change. 
% The design pattern is implemented in the application to be observed. 
% The observer pattern relies on the application to generate the required notifications, however in our case we cannot anticipate which event should be triggered and where and when this should happen.
% This constraint significantly raises the complexity of implementing \project.

% However, our case is slightly different since applications can not always be prepared for an eventual profiling since a programmer cannot reliably predict which part of the software will have to be profiled in the future. 
% This constraint significantly raises the complexity of implementing \project. 

\project has two ways of implementing an observer: registering the observer to preexistent event-based systems, or using the meta-level programming techniques of the host language.

Lets consider the class \co{AnnouncementObserver}, whose responsibility is to observe the generation of specific announcements.

\begin{lstlisting}
<b>AnnouncementObserver>>install</b>
	self announcer 
			on: Announcement 
			send: #value: 
			to: self handler
\end{lstlisting}

The \co{install} method installs an observer object on the domain specified in the \co{install} method. In the previous snippet of code we can see that the observer is hooked into the announcement system by evaluating the observer's handler when an announcement is triggered.

However, not all profiling activities can rely in a preexistent mechanism for registering to events. Because of this, we need to rely on the meta-programming facilities of the host language.
These facilities are not always uniform and require ad-hoc code to hook behavior in.
To avoid this drawback we decided to use a framework that provides uniform meta-programming abstractions.
Albedo~\cite{Ress10a} is a model of fined-grained unanticipated dynamic structural and behavioral adaptation. Instead of providing reflective capabilities as an external mechanism Albedo integrates them deeply in the environment. 
Albedo is a reflective system based on explicit meta-objects to improve meta-level engineering.


%Albedo~\cite{Ress10a} is a model of fined-grained unanticipated dynamic structural and behavioral adaptation. Instead of providing reflective capabilities as an external mechanism Albedo integrates them deeply in the environment. 
%Albedo is a reflective system based on explicit meta-objects, and present a series of examples illustrating how these explicit meta-objects fulfill established requirements while improving engineering at the meta-level.

Albedo's meta-objects provide a structural view and a behavioral view. In the context of \project we were mainly interested in the behavioral reifications. A behavioral meta-object reifying message send was used for the message send observer. As well as a behavioral meta-object for reifying received message. State read and write are also supported by behavioral meta-objects thus \project can profile this dynamic events.
Albedo meta-objects when attached to a single object are object-specific in nature thus fulfilling an important domain-specific profiler design requirement.

Lets consider the Message Received Observer, whose responsibility is to observe when an specific object receives an specific message.

%\lr{I would only put numbers if you refer to them}

\begin{lstlisting}
<b>MessageReceivedObserver>>install</b>
	self observerMetaObject boundTo: self object
\end{lstlisting}

\begin{lstlisting}
<b>MessageReceivedObserver>>setUp</b>
	profilingMetaObject := BehaviorMetaObject new 
								when: self selector 
								isReceivedDo: self handler
\end{lstlisting}
The method \ct{install} binds a meta-object to the object to be observed.
The method \ct{setUp} initializes the profiling meta-object with a behavioral meta-object. 
This meta-object evaluates the handler when a specific message is received by the profiled object. This mechanism is termed \emph{object-specific instrumentation}.

Object-specific instrumentation is not trivial to achieve in class-based languages like Smalltalk and Java \ab{without a significant overhead? AspectJ has a perObject keyword I think}. 
Classes are deeply rooted in the language interpreter or virtual machine and its performance is tweaked to rely heavily on this constructs.
Moreover, most languages provide a good level of structural reflection which deals with language structural elements like classes, method, statements, \etc
But most languages do not provide a standard mechanism to reflect on the dynamic abstraction of the language.
There are no abstractions for meta-events like a message send, a message receive, a state read, \etc.

Albedo has been designed as an evolution of partial behavioral reflection for Smalltalk, which in turn was conceived as an extension of the Reflex~\cite{Tant03a}.
\ab{is the following important? I would comment out all the remaining}Since Reflex was originally realized with Java, the Albedo approach would be achievable in a more static mainstream language like Java. 
%The reason for choosing Pharo Smalltalk for implementing Albedo is that it more naturally supports \emph{unanticipated} use of reflection at run-time and supports an AST-based reflective code model.
However, a Java solution would be more static in nature: it would not be possible to remove meta-objects completely (as code cannot be changed at run-time) and the code model would not be as closely integrated with the run-time of the language.



%:========
\subsection{Benchmark}	

Profiling always impact the performance of the application being analyze. 
We have performed a micro-benchmark to assess the maximal performance impact of \project. 
We assume that the behavior required to fulfill the profiling requirements is constant to any observer technique.
\project has two mechanism to observe and application: to registering the observer to preexistent event-based systems, or using the meta-level programming techniques of the host language.

We analyze the impact of \project on both profiling uses cases. All benchmarks were performed on an Apple MacBook Pro, 2.16 GHz Intel Core Duo in Pharo~1.1.1 with the jitted Cog VM. 
%To avoid possible execution artifacts disturbing the benchmark we ensure that the involved reflective and jitted methods are created in advance and that method lookup caches are filled.

\jr{here we need to show two uses cases one for registration and the other for reflection.}

\jr{I do not know if we really have to say something about this here.}
This micro-benchmark shows that reflection on a runtime system can have a significant performance impact. However, for real-world application with only few reifications the performance impact is significantly lower. Albedo's meta-objects provide a way of adapting selected objects thus allowing reflection to be applied within a fine-grained scope only. This provides a natural way of controlling the performance impact of reflective changes.

	
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Conclusion}\seclabel{conclusion}

\jr{The first paragraph does not make sense to me, what is the idea?}
This problem is rather well generalized. For example, profiling a virtual machine is a particularly difficult activity, since instead of providing information about bytecode and primitive executions, the virtual machine talks about functions executions\footnote{\url{http://www.mirandabanda.org/cogblog/2008/12/30/the-idee-fixe-and-the-perfected-profiler/}}.

Our case studies have shown the need for domain-specific profiler. 
We have identified the properties a domain-specific profiler must have.
We have presented \project, a prototype for building domain-specific profiler following those properties.

\jr{What else can we say? Future work?}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section*{Acknowledgments}

\small We gratefully acknowledge the financial support of the Swiss National Science Foundation for the project ``Synchronizing Models and Code" (SNF Project No.\ 200020-131827, Oct.\ 2010 -- Sept.\ 2012).

% bibliography
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\bibliographystyle{splncs}
\bibliography{scg}

\end{document}